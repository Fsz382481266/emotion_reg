{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ER_LSTM",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6wGFOL9YjJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0155f1a7-319b-4d7a-db06-71b6f35b1bb2"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbkRAJ7NYuTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "0e5b60ee-1930-4dc5-b2fa-eecc8d4eca60"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Mar 14 12:11:36 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.59       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8     9W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYev3I7UY61E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "266b7da1-185e-4447-cb7c-2aec06a12e14"
      },
      "source": [
        "import os \n",
        "\n",
        "os.chdir('drive/My Drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f588ff6f20a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyCy105i6AP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQs9FMukZUqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "afd1e362-ad5c-49a6-ffa5-7135eb97b7dc"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"nCov_10k_test.csv\")\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>微博id</th>\n",
              "      <th>微博发布时间</th>\n",
              "      <th>发布人账号</th>\n",
              "      <th>微博中文内容</th>\n",
              "      <th>微博图片</th>\n",
              "      <th>微博视频</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4456068992182160</td>\n",
              "      <td>01月01日 23:38</td>\n",
              "      <td>-精緻的豬豬女戰士-</td>\n",
              "      <td>#你好2020#新年第一天元气满满的早起出门买早饭结果高估了自己抗冻能力回家成功冻发烧（大概...</td>\n",
              "      <td>['https://ww2.sinaimg.cn/thumb150/745aa591ly1g...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4456424178427250</td>\n",
              "      <td>01月02日 23:09</td>\n",
              "      <td>liujunyi88</td>\n",
              "      <td>大宝又感冒鼻塞咳嗽了，还有发烧。队友加班几天不回。感觉自己的情绪在家已然是随时引爆的状态。情...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4456797466940200</td>\n",
              "      <td>01月03日 23:53</td>\n",
              "      <td>ablsa</td>\n",
              "      <td>还要去输两天液，这天也太容易感冒发烧了，一定要多喝热水啊?</td>\n",
              "      <td>['https://ww3.sinaimg.cn/orj360/006fTidCly1gaj...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4456791021108920</td>\n",
              "      <td>01月03日 23:27</td>\n",
              "      <td>喵吃鱼干Lynn</td>\n",
              "      <td>我太难了别人怎么发烧都没事就我一检查甲型流感?</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4457086404997440</td>\n",
              "      <td>01月04日 19:01</td>\n",
              "      <td>我的发小今年必脱单</td>\n",
              "      <td>果然是要病一场的喽回来第三天开始感冒今儿还发烧了喉咙眼睛都难受的一匹怎么样能不经意让我的毕设...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               微博id  ... 微博视频\n",
              "0  4456068992182160  ...   []\n",
              "1  4456424178427250  ...   []\n",
              "2  4456797466940200  ...   []\n",
              "3  4456791021108920  ...   []\n",
              "4  4457086404997440  ...   []\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8m5SpZbZZyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jieba\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.word2vec import PathLineSentences\n",
        "import gensim\n",
        "from itertools import chain\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data.dataloader as dataloader\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "import torchtext.vocab as torchvocab\n",
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import accuracy_score,recall_score,f1_score\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2IAwxgX508Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSJFIwLIZdWw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "63789297-eed6-487e-ffe8-8a109c457340"
      },
      "source": [
        "train_df = pd.read_csv('nCoV_100k_train.labled.csv',)\n",
        "train_df['word']=train_df[\"微博中文内容\"]\n",
        "train_df['label']=train_df[\"情感倾向\"]\n",
        "train_df['wordcut']=train_df['word'].astype(str).apply(lambda x: jieba.lcut(x))\n",
        "train_df1 = train_df.copy()\n",
        "train_df1=train_df1.drop(labels=['微博id','微博发布时间',\"发布人账号\",'微博中文内容','微博图片','微博视频','情感倾向'],axis=1)\n",
        "letters = ['word','wordcut','label']\n",
        "train_df1=train_df1[letters]\n",
        "train_df1=train_df1[~train_df1['label'].isin(['9','-','·'])]\n",
        "train_df1 = train_df1.fillna(10)\n",
        "train_df1=train_df1[~train_df1['label'].isin(['-2','10','4',10])]\n",
        "train_df1.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Loading model from cache /tmp/jieba.cache\n",
            "Loading model cost 0.649 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 99913 entries, 0 to 99999\n",
            "Data columns (total 3 columns):\n",
            "word       99913 non-null object\n",
            "wordcut    99913 non-null object\n",
            "label      99913 non-null object\n",
            "dtypes: object(3)\n",
            "memory usage: 3.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LwGhI8-bvof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cda0c285-3d7f-4fd6-e60c-2e122d516e16"
      },
      "source": [
        "test_df = pd.read_csv('nCov_10k_test.csv',header= 0)\n",
        "test_df['word']=test_df[\"微博中文内容\"]\n",
        "test_df['label']=None\n",
        "test_df['wordcut']=test_df['word'].astype(str).apply(lambda x: jieba.lcut(x))\n",
        "df1_test = test_df.copy()\n",
        "df1_test=df1_test.drop(labels=['微博id','微博发布时间',\"发布人账号\",'微博中文内容','微博图片','微博视频'],axis=1)\n",
        "letters_test = ['word','wordcut','label']\n",
        "df1_test=df1_test[letters_test]\n",
        "test_tokenized = df1_test['wordcut'].tolist()\n",
        "len(test_tokenized)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R_z6WuCZgx-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4092de29-6269-44a6-e29b-ce4b2743b50b"
      },
      "source": [
        "w2v = Word2Vec(size=100,min_count=10)\n",
        "x = train_df1['wordcut']\n",
        "w2v.build_vocab(x)\n",
        "w2v.train(x, total_examples=w2v.corpus_count,epochs=w2v.epochs)\n",
        "w2v.save(\"Word2vec_1003k.w2v\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFd93aajgFjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df1['label'].loc[train_df1['label']== '-1'] = '2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7H0wIaAfWfE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4c709270-d5c3-4d58-8768-0d276c0dbb7c"
      },
      "source": [
        "wvmodelwvmodel = gensim.models.word2vec.Word2Vec.load(\"Word2vec_1003k.w2v\").wv\n",
        "vocab = set(chain(*train_df1['wordcut'].tolist()))\n",
        "vocab_size = len(vocab)\n",
        "train_tokenized = train_df1['wordcut'].tolist()\n",
        "word_to_idx = {word: i+1 for i, word in enumerate(vocab)}\n",
        "word_to_idx['<unk>'] = 0\n",
        "idx_to_word = {i+1: word for i, word in enumerate(vocab)}\n",
        "idx_to_word[0] = '<unk>'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRrusofWZk5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_samples(tokenized_samples,vocab):\n",
        "    features = []\n",
        "    for sample in tokenized_samples:\n",
        "        feature = []\n",
        "        for token in sample:\n",
        "            if token in word_to_idx:\n",
        "                feature.append(word_to_idx[token])\n",
        "            else:\n",
        "                feature.append(0)\n",
        "        features.append(feature)\n",
        "    return features\n",
        "def pad_samples(features,maxlen=100,PAD=0):\n",
        "    padded_features = []\n",
        "    for feature in features:\n",
        "        if len(feature) >=maxlen:\n",
        "            padded_feature = feature[:maxlen]\n",
        "        else:\n",
        "            padded_feature = feature\n",
        "            while(len(padded_feature) <maxlen):\n",
        "                padded_feature.append(PAD)\n",
        "        padded_features.append(padded_feature)\n",
        "    return padded_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5WxjeJUZ3-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = torch.tensor(pad_samples(encode_samples(train_tokenized,vocab)))\n",
        "train_labels = torch.tensor([int(score) for score in train_df1[\"label\"].tolist()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYuGEeLAkYj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdEDk0COaBAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentNet(nn.Module):\n",
        "    def __init__(self,vocab_size,embed_size,num_hiddens,num_layers,\n",
        "                bidirectional,weight,labels,use_gpu,**kwargs):\n",
        "        super(SentimentNet,self).__init__(**kwargs)\n",
        "        self.num_hiddens = num_hiddens\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.bidirectional = bidirectional\n",
        "        self.embedding = nn.Embedding.from_pretrained(weight)\n",
        "        self.embedding.weight.requires_grad =False\n",
        "        self.encoder = nn.LSTM(input_size=embed_size, hidden_size=self.num_hiddens,\n",
        "                               num_layers=num_layers, bidirectional=self.bidirectional,\n",
        "                               dropout=0)\n",
        "        if self.bidirectional:\n",
        "            self.decoder = nn.Linear(num_hiddens * 4,labels)\n",
        "        else:\n",
        "            self.decoder = nn.Linear(num_hiddens * 2,labels)\n",
        "            \n",
        "    def forward(self,inputs):\n",
        "        embeddings = self.embedding(inputs)\n",
        "        states,hidden = self.encoder(embeddings.permute([1,0,2]))\n",
        "        encoding = torch.cat([states[0],states[-1]],dim=1)\n",
        "        outputs = self.decoder(encoding)\n",
        "        return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpmHusRAaKSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 3\n",
        "embed_size = 100\n",
        "num_hiddens = 100\n",
        "num_layers = 2\n",
        "bidirectional = True\n",
        "batch_size = 64\n",
        "labels = 3\n",
        "lr = 0.01\n",
        "device = torch.device('cuda:0')\n",
        "use_gpu = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gugUfMx3aOMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight = torch.zeros(vocab_size+1, embed_size)\n",
        "for i in range(len(wvmodelwvmodel.index2word)):\n",
        "    try:\n",
        "        index = word_to_idx[wvmodelwvmodel.index2word[i]]\n",
        "    except:\n",
        "        continue\n",
        "    weight[index,:] = torch.from_numpy(wvmodelwvmodel.get_vector(\n",
        "    idx_to_word[word_to_idx[wvmodelwvmodel.index2word[i]]]))\n",
        "\n",
        "net = SentimentNet(vocab_size=(vocab_size+1), embed_size=embed_size,\n",
        "                   num_hiddens=num_hiddens, num_layers=num_layers,\n",
        "                   bidirectional=bidirectional, weight=weight,\n",
        "                   labels=labels, use_gpu=use_gpu)\n",
        "net.to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRaTXqlDaV2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4502761b-91a3-412c-d03e-79f00ee460bb"
      },
      "source": [
        "print(\"data load...\")\n",
        "train_set = torch.utils.data.TensorDataset(train_features, train_labels)\n",
        "train_iter = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                         shuffle=True)\n",
        "test_features = torch.tensor(pad_samples(encode_samples(test_tokenized, vocab)))\n",
        "test_labels = torch.tensor([0 for score in range(10000)])\n",
        "\n",
        "test_set = torch.utils.data.TensorDataset(test_features, test_labels)\n",
        "test_iter = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
        "                                        shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data load...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVcz1jYAgTBJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4293e998-d8fd-4ccf-c21a-a1b668cb5794"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EspdBGyJaZrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"model train ...\")\n",
        "predlist = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    train_rec = 0\n",
        "    train_f1 = 0\n",
        "    n= 0\n",
        "    for feature,label in train_iter:\n",
        "        n += 1\n",
        "        net.zero_grad()\n",
        "        feature = Variable(feature.cuda())\n",
        "        label = Variable(label.cuda())\n",
        "        score = net(feature)\n",
        "        loss = loss_function(score, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_acc += accuracy_score(torch.argmax(score.cpu().data,dim=1),label.cpu())\n",
        "        train_rec += recall_score(torch.argmax(score.cpu().data,dim=1),label.cpu(),average='macro')\n",
        "        train_f1 += f1_score(torch.argmax(score.cpu().data,dim=1),label.cpu(),average='macro')\n",
        "\n",
        "        train_loss += loss\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for test_feature, test_label in test_iter:\n",
        "            test_feature = Variable(test_feature.cuda())\n",
        "            test_label = Variable(test_label)\n",
        "            test_score = net(test_feature)\n",
        "            predlist.append(torch.argmax(test_score.data,dim=1))          \n",
        "    # print(predlist)\n",
        "    if epoch < num_epochs-1:\n",
        "        predlist = []\n",
        "    print(predlist)\n",
        "    end = time.time()\n",
        "    runtime = end-start\n",
        "    print('epoch: %d, train loss: %.4f,train acc: %.2f,train recall: %.2f,train f1: %.2f,time: %.2f' %\n",
        "         (epoch,train_loss.data / n, train_acc / n , train_rec / n , train_f1 / n , runtime))\n",
        "print(\"model train end\")\n",
        "torch.save (net.state_dict(), 'params3.pk1') \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bUGtmw0AH9c",
        "colab_type": "text"
      },
      "source": [
        "epoch: 0, train loss: 0.6857,train acc: 0.70,train recall: 0.67,train f1: 0.62,time: 31.50\n",
        "\n",
        "\n",
        "epoch: 1, train loss: 0.6262,train acc: 0.73,train recall: 0.71,train f1: 0.66,time: 31.53\n",
        "\n",
        "epoch: 2, train loss: 0.6115,train acc: 0.73,train recall: 0.71,train f1: 0.67,time: 31.87\n",
        "\n",
        "\n",
        "model train end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4Tgx3rJac-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbc144b7-7dea-491b-b04c-9d5a0d5d4992"
      },
      "source": [
        "len(predlist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGU-XPVvaxK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.load_state_dict(torch.load('params3.pk1'))  #加载模型\n",
        "predlist1 = []\n",
        "\n",
        "for test_feature, test_label in test_iter:\n",
        "    test_feature = Variable(test_feature.cuda())\n",
        "    test_label = Variable(test_label.cuda())\n",
        "    test_score = net(test_feature)\n",
        "    predlist1.append(torch.argmax(test_score.data,dim=1))          \n",
        "print(predlist1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRXOy8Y6fOaA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cdba5d9-7178-4965-951f-b118abf31b13"
      },
      "source": [
        "0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0\n",
        "0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0\n",
        "len(predlist1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz-nJvItifL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59a814c1-96d2-4cbd-f8c4-22362a57cb88"
      },
      "source": [
        "abblist=[]\n",
        "for i in range(157):\n",
        "    if i<156:\n",
        "        for j in range(64): \n",
        "            if int(predlist[i][j]) ==2:\n",
        "                abblist.append(-1)\n",
        "            else:\n",
        "                abblist.append(int(predlist[i][j]))\n",
        "    else:\n",
        "        for j in range(16):\n",
        "            if int(predlist[i][j]) ==2:\n",
        "                abblist.append(-1)\n",
        "            else:\n",
        "                abblist.append(int(predlist[i][j]))\n",
        "dic={}\n",
        "for i in abblist:\n",
        "    dic[i] = abblist.count(i)\n",
        "dic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{-1: 1298, 0: 6560, 1: 2142}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or1RDSc9A_aC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41fea561-a6b4-4e99-c02a-01e5e6f89898"
      },
      "source": [
        "abblist1=[]\n",
        "for i in range(157):\n",
        "    if i<156:\n",
        "        for j in range(64): \n",
        "            if int(predlist1[i][j]) ==2:\n",
        "                abblist1.append(-1)\n",
        "            else:\n",
        "                abblist1.append(int(predlist[i][j]))\n",
        "    else:\n",
        "        for j in range(16):\n",
        "            if int(predlist1[i][j]) ==2:\n",
        "                abblist1.append(-1)\n",
        "            else:\n",
        "                abblist1.append(int(predlist[i][j]))\n",
        "dic1={}\n",
        "for i in abblist1:\n",
        "    dic1[i] = abblist1.count(i)\n",
        "dic1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{-1: 1298, 0: 6560, 1: 2142}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCE5s14eBKy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}